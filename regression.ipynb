{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSc Research Project - Coding Exercise - Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path().absolute() / 'four_outputs_liqcf_pacific.csv'\n",
    "df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['tot_aod', 'RH700', 'RH850', 'w500', 'whoi_sst']\n",
    "target_name = 'cod'\n",
    "X, y = df[features], df[target_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split_no_sk(X, y, train_size, valid_size, test_size):\n",
    "    assert(train_size+valid_size+test_size == 1)\n",
    "    assert(len(X) == len(y))\n",
    "    N = len(X)\n",
    "    train_idx, val_idx, test_idx  = np.split(np.random.permutation(N), [int(N*train_size), int(N*(train_size+valid_size))])\n",
    "    return X.iloc[train_idx], y.iloc[train_idx], X.iloc[val_idx], y.iloc[val_idx], X.iloc[test_idx], y.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split_sk(X, y, train_size, valid_size, test_size):\n",
    "    assert(train_size+valid_size+test_size == 1)\n",
    "    assert(len(X) == len(y))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=valid_size/(train_size+valid_size))\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_linreg(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Input: training and testing sets\n",
    "    Output: coefficient of determination of the prediction, R^2,\n",
    "            we want it to be as closed to 1.0 as possible\n",
    "    \"\"\"\n",
    "    pipeline = make_pipeline(StandardScaler(), LinearRegression())\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    return pipeline.score(X_test, y_test)\n",
    "\n",
    "def complete_linreg(X, y):\n",
    "    scores = []\n",
    "    for _ in range(10):\n",
    "        X_train, y_train, _, _, X_test, y_test = data_split_no_sk(X, y, 0.9, 0, 0.1)\n",
    "        score = train_test_linreg(X_train, y_train, X_test, y_test)\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "scores_linreg = complete_linreg(X, y)\n",
    "scores_linreg_avg = np.mean(scores_linreg)\n",
    "print(scores_linreg, scores_linreg_avg)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Basis Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_polyreg(X_train, y_train, X_test, y_test, deg):\n",
    "    \"\"\"\n",
    "    Input: training set, testing set, and degree for polynomial expansion\n",
    "    Output: coefficient of determination of the prediction, R^2,\n",
    "            we want it to be as closed to 1.0 as possible\n",
    "    \"\"\"\n",
    "    pipeline = make_pipeline(PolynomialFeatures(degree=deg), StandardScaler(), LinearRegression())\n",
    "    # poly = PolynomialFeatures(degree=deg)\n",
    "    # X_train_ = poly.fit_transform(X_train)\n",
    "    # X_test_ = poly.fit_transform(X_test)\n",
    "    # model = LinearRegression()\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    return pipeline.score(X_test, y_test)\n",
    "\n",
    "def fit_parameters_polyreg(X, y):\n",
    "    scores = []\n",
    "    X_train, y_train, _, _, X_test, y_test = data_split_no_sk(X, y, 0.9, 0, 0.1)\n",
    "    for deg in range(1, 6):\n",
    "        score = train_test_polyreg(X_train, y_train, X_test, y_test, deg)\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "def complete_polyreg(X, y, deg):\n",
    "    scores = []\n",
    "    for _ in range(10):\n",
    "        X_train, y_train, _, _, X_test, y_test = data_split_no_sk(X, y, 0.9, 0, 0.1)\n",
    "        score = train_test_polyreg(X_train, y_train, X_test, y_test, deg)\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "# scores = fit_parameters_polyreg(X, y)\n",
    "# print(scores)\n",
    "\n",
    "full_scores_polyreg = complete_polyreg(X, y, 5)\n",
    "scores_polyreg_avg = np.mean(full_scores_polyreg)\n",
    "print(full_scores_polyreg, scores_polyreg_avg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_mlp1(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Input: training (including validation) and testing sets\n",
    "    Output: coefficient of determination of the prediction, R^2,\n",
    "            we want it to be as closed to 1.0 as possible\n",
    "    \"\"\"\n",
    "    pipeline = make_pipeline(StandardScaler(), MLPRegressor(hidden_layer_sizes=(100, ), activation=\"relu\", solver=\"adam\", early_stopping=True, validation_fraction=0.1, verbose=True, n_iter_no_change=2))\n",
    "    pipeline.fit(X_train.values, y_train)\n",
    "    return pipeline.score(X_test.values, y_test)\n",
    "\n",
    "def complete_mlp1(X, y):\n",
    "    scores = []\n",
    "    for _ in range(10):\n",
    "        X_train, y_train, _, _, X_test, y_test = data_split_no_sk(X, y, 0.9, 0, 0.1)\n",
    "        score = train_val_test_mlp1(X_train, y_train, X_test, y_test)\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "scores_mlp1 = complete_mlp1(X, y)\n",
    "scores_mlp1_avg = np.mean(scores_mlp1)\n",
    "print(scores_mlp1, scores_mlp1_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_mlp2(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Input: training (including validation) and testing sets\n",
    "    Output: coefficient of determination of the prediction, R^2,\n",
    "            we want it to be as closed to 1.0 as possible\n",
    "    \"\"\"\n",
    "    pipeline = make_pipeline(StandardScaler(), MLPRegressor(hidden_layer_sizes=(100, 50, ), activation=\"relu\", solver=\"adam\", early_stopping=True, validation_fraction=0.1, verbose=True, n_iter_no_change=2))\n",
    "    pipeline.fit(X_train.values, y_train)\n",
    "    return pipeline.score(X_test.values, y_test)\n",
    "\n",
    "def complete_mlp2(X, y):\n",
    "    scores = []\n",
    "    for _ in range(10):\n",
    "        X_train, y_train, _, _, X_test, y_test = data_split_no_sk(X, y, 0.9, 0, 0.1)\n",
    "        score = train_val_test_mlp2(X_train, y_train, X_test, y_test)\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "scores_mlp2 = complete_mlp2(X, y)\n",
    "scores_mlp2_avg = np.mean(scores_mlp2)\n",
    "print(scores_mlp2, scores_mlp2_avg)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2609836915d5882a9ab5e12d208b958ece84be5c4203a7610fe5b746fe5d0b39"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('atml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
